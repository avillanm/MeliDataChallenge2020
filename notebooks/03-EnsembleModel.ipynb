{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "\n",
    "En este notebook se prepara el ensamble de modelos usado en la última submission. El valor **ncdg** en el **leaderboard** público fue **0.31293** consiguiendo la segunda posición.\n",
    "\n",
    "### Summary\n",
    "\n",
    "El ensamble consiste en tomar las predicciones de los 2 modelos de factorización de matrices (MF) entrenados (notebook 02-AlternatingLeastSquaresModel). Se tomaron hasta las 50 mejores predicciones promediando sus scores.\n",
    "\n",
    "La segunda parte consiste en scorear a los productos visitados en la sesión (considerando los pesos por posición). Este simple enfoque que consigue buenos resultados, permite complementar a los modelos MF, sobre todo en los casos de visitas en ítems que no se usaron en el entrenamiento (limitación de cold start). Se normalizan los scores entre 0 y 1 para ponerlos en la misma escala que las predicciones de MF.\n",
    "\n",
    "Se combinan las predicciones usando una suma de scores por pesos, dándole más importancia a la predicciones MF. Y finalmente si las primeras 3 predicciones tienen un score alto, solo se seleccionan ítems de esos dominios en la predicción.\n",
    "\n",
    "### Resultados\n",
    "\n",
    "El valor **ncdg** en test fue **0.3180** y en validación **0.3186**. Tomando el dominio del primer producto recomendado, se logra un accuracy de **0.42** sobre el dominio del producto comprado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import heapq\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lee del catatálogo los dominios de los productos (se usa en la evalaución)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_TO_DOMAIN = {}\n",
    "with open(\"./data/item_data.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        data = json.loads(line)\n",
    "        ITEM_TO_DOMAIN[data[\"item_id\"]] = data[\"domain_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_TO_COUNTRY = {}\n",
    "with open(\"./data/item_data.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        data = json.loads(line)\n",
    "        ITEM_TO_COUNTRY[data[\"item_id\"]] =data[\"category_id\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDCG = np.sum([(1 if i != 1 else 12) / np.log2(1 + i) for i in range(1, 11)])\n",
    "\n",
    "def dcg(rec, y_item_id, n=10):\n",
    "    y_domain = ITEM_TO_DOMAIN[y_item_id]\n",
    "    \n",
    "    return np.sum([(1 if yhat_item_id != y_item_id else 12) / np.log2(1 + i)\\\n",
    "                   for i, yhat_item_id in enumerate(rec[:n], 1)\\\n",
    "                  if (ITEM_TO_DOMAIN[yhat_item_id] == y_domain)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los productos sin precio o dominio se excluyen de las recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK_LIST = set()\n",
    "with open(\"./data/item_data.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        data = json.loads(line)\n",
    "        if (data[\"domain_id\"]== None):\n",
    "            BLACK_LIST.add(data[\"item_id\"]) \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "851"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BLACK_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lee recomendaciones de modelos de factorización de matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/models/implicit_test_reco_scores_model1.pkl\", \"rb\") as fd:\n",
    "    test_mf_vars = pickle.load(fd)\n",
    "    test_mf_scores = test_mf_vars[\"test_reco_scores\"]\n",
    "    val_mf_scores = test_mf_vars[\"val_reco_scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/models/implicit_test_reco_scores_model2.pkl\", \"rb\") as fd:\n",
    "    test_mf_vars = pickle.load(fd)\n",
    "    test_mf_scores_2 =  test_mf_vars[\"test_reco_scores\"]\n",
    "    val_mf_scores_2 = test_mf_vars[\"val_reco_scores\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/models/implicit_matrix_variables.pkl\", \"rb\") as fd:\n",
    "    ITEM_TO_IDX = pickle.load(fd)[\"ITEM_TO_IDX\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomendaciones por popularidad\n",
    "\n",
    "Se usan como relleno (cold-start).\n",
    "\n",
    "Se toman productos más visitados, y más visitados por dominio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_viewed_items = Counter()\n",
    "most_viewed_by_domain = {}\n",
    "\n",
    "line_idx = 0\n",
    "with open(\"./data/train_dataset.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        line_idx += 1\n",
    "        data = json.loads(line)\n",
    "        view = [event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"view\"]\n",
    "        views_counter.update(view)\n",
    "\n",
    "        for item_id in set(view):\n",
    "            domain = ITEM_TO_DOMAIN[item_id]\n",
    "            if not domain in most_viewed_by_domain:\n",
    "                most_viewed_by_domain[domain] = Counter()\n",
    "            most_viewed_by_domain[domain][item_id] +=1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más visitados por país"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_viewed_items_br =[item_id for item_id, _ in\n",
    "    Counter({item_id: count for item_id, count\\\n",
    "             in most_viewed_items.items() if ITEM_TO_COUNTRY[item_id] == \"B\" }).most_common(10)]\n",
    "\n",
    "most_viewed_items_mx  =[item_id for item_id, _ in\n",
    "    Counter({item_id: count for item_id, count\\\n",
    "             in most_viewed_items.items() if ITEM_TO_COUNTRY[item_id] == \"M\" }).most_common(10)]\n",
    "\n",
    "\n",
    "views_counter = most_viewed_items\n",
    "\n",
    "most_viewed_items = [item for item, _ in most_viewed_items.most_common(10)]\n",
    "\n",
    "for domain, counter in most_viewed_by_domain.items():\n",
    "    most_viewed_by_domain[domain] = [item for item, _ in counter.most_common(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para rellenar recomendaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_rec(rec, fill, n=10 ):\n",
    "    assert len(fill) >= n\n",
    "    fill_index = 0\n",
    "    while len(rec) < n:\n",
    "        if fill[fill_index] not in rec:\n",
    "            rec.append(fill[fill_index] )\n",
    "        fill_index += 1\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensamble de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "W0 = 1.0 # peso usado para predicciones por visitas\n",
    "WI = 1.5 # peso usado para predicciones de MF\n",
    "\n",
    "n_recs = 0\n",
    "y_test = []\n",
    "model_sum_dcg = 0.0\n",
    "tp_domain = 0\n",
    "with open(\"./data/train_dataset-test_split.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        data = json.loads(line)\n",
    "        item_bought = data[\"item_bought\"]\n",
    "        items_views = [event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"view\"]\n",
    "        y_test.append(item_bought)\n",
    "        \n",
    "        # promedia predicciones por modelos MF\n",
    "        model_rec_scores = {i:s for i, s in test_mf_scores[n_recs]}\n",
    "        model_rec_scores_2 =  {i:s for i, s in test_mf_scores_2[n_recs]}\n",
    "        model_rec_scores = {i: (model_rec_scores.get(i, 0) *0.5 +\\\n",
    "                                model_rec_scores_2.get(i, 0) * 0.5)\n",
    "                            for i in (model_rec_scores.keys() | model_rec_scores_2.keys())}\n",
    "        \n",
    "        # Ranking de items visitados\n",
    "        items_pv_count = {}\n",
    "        items_views = items_views[::-1]            \n",
    "        for pos, item_view in enumerate(items_views, 1):\n",
    "            items_pv_count[item_view] = items_pv_count.get(item_view,0) + 1 / np.log10(pos + 1)\n",
    "        \n",
    "        rec_scores = defaultdict(dict)\n",
    "        # scores por visitas\n",
    "        for item_view, pv_count in items_pv_count.items():\n",
    "            # Asigna un score por item visitado\n",
    "            rec_scores[item_view] = rec_scores.get(item_view, 0) + pv_count \n",
    "        \n",
    "        # normaliza scores por visitas\n",
    "        sum_scores = sum([s for s in rec_scores.values()])\n",
    "        if sum_scores:\n",
    "            c = ITEM_TO_COUNTRY[items_views[0]]\n",
    "            rec_scores = {i: s / sum_scores  for i, s in rec_scores.items() }\n",
    "        # excluye recomendaciones de bajo score\n",
    "        rec_scores = {i: s for i, s in rec_scores.items() if s > 0.05}\n",
    "        \n",
    "        # Suma ambos scores usando pesos. Si el item_id no se uso en el entrenamiento modelo de MF, suma una constante.\n",
    "        rec_scores = {i: model_rec_scores.get(i, 0) * WI + rec_scores.get(i, 0) * W0 + 0 if i in ITEM_TO_IDX else 0.2\\\n",
    "             for i in (rec_scores.keys() | model_rec_scores.keys()) if not i in BLACK_LIST }\n",
    "        \n",
    "        # ordena por score\n",
    "        rec = [item for item, score in heapq.nlargest(50, rec_scores.items(), key=lambda item: item[1])]\n",
    "        \n",
    "        # selecciona los dominios de los top 3 productos si es que cumplen con un threshold\n",
    "        domains = set([ITEM_TO_DOMAIN[rec[i]] for i in range(3) if rec_scores[rec[i]] >= 1])\n",
    "        rec_fill = [r for r in rec if rec_scores[r]]\n",
    "        \n",
    "        # se se seleccionan dominios, utiliza este filtro en la recomendaciones\n",
    "        if domains:\n",
    "            rec = [r for r in rec if ITEM_TO_DOMAIN[r] in domains]\n",
    "            rec_fill = [r for r in rec_fill if r not in rec]\n",
    "\n",
    "        #pass\n",
    "        rec = rec[:10]\n",
    "        \n",
    "\n",
    "        # rellena en caso de no tener recomendaciones\n",
    "        if len(rec) < 10:\n",
    "            if len(rec):\n",
    "                # rellena con más visitados de los dominios de selección\n",
    "                fill_scores = {r: views_counter[r]  for domain_i in domains for r in most_viewed_by_domain.get(domain_i, [])}                \n",
    "                fill = [item for item, score in heapq.nlargest(10, fill_scores.items(), key=lambda item: item[1])]\n",
    "                if len(fill) < 10:\n",
    "                    # si no alcanza, agrega los descartados en la selección de dominios\n",
    "                    fill += rec_fill\n",
    "            else: \n",
    "                fill = most_viewed_items\n",
    "            rec = fill_rec(rec, fill)\n",
    "        assert len(rec) == 10\n",
    "        \n",
    "        # evaluación\n",
    "        model_sum_dcg += dcg(rec, item_bought)\n",
    "        \n",
    "        rec_dom = ITEM_TO_DOMAIN[rec[0]]\n",
    "        tp_domain += ITEM_TO_DOMAIN[item_bought] in rec_dom\n",
    "        \n",
    "        n_recs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:  0.3180 (20000 recomendaciones)\n"
     ]
    }
   ],
   "source": [
    "print(f\"NDCG: {model_sum_dcg / (IDCG * n_recs): .4f} ({n_recs} recomendaciones)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (domain):  0.4180 (20000 recomendaciones)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy (domain): {tp_domain / n_recs: .4f} ({n_recs} recomendaciones)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación en validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "W0 = 1.0 \n",
    "WI = 1.5\n",
    "\n",
    "n_recs = 0\n",
    "y_val = []\n",
    "model_sum_dcg = 0.0\n",
    "tp_domain = 0\n",
    "with open(\"./data/train_dataset-val_split.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "        except:\n",
    "            continue\n",
    "        item_bought = data[\"item_bought\"]\n",
    "        items_views = [event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"view\"]\n",
    "        y_val.append(item_bought)\n",
    "        \n",
    "        # promedia predicciones por modelos MF\n",
    "        model_rec_scores = {i:s for i, s in val_mf_scores[n_recs]}\n",
    "        model_rec_scores_2 =  {i:s for i, s in val_mf_scores_2[n_recs]}\n",
    "        model_rec_scores = {i: (model_rec_scores.get(i, 0) *0.5 +\\\n",
    "                                model_rec_scores_2.get(i, 0) * 0.5)\n",
    "                            for i in (model_rec_scores.keys() | model_rec_scores_2.keys())}\n",
    "        \n",
    "        # Ranking de items visitados\n",
    "        items_pv_count = {}\n",
    "        items_views = items_views[::-1]            \n",
    "        for pos, item_view in enumerate(items_views, 1):\n",
    "            items_pv_count[item_view] = items_pv_count.get(item_view,0) + 1 / np.log10(pos + 1)\n",
    "        \n",
    "        rec_scores = defaultdict(dict)\n",
    "        # scores por visitas\n",
    "        for item_view, pv_count in items_pv_count.items():\n",
    "            # Asigna un score por item visitado\n",
    "            rec_scores[item_view] = rec_scores.get(item_view, 0) + pv_count \n",
    "        \n",
    "        # normaliza scores por visitas\n",
    "        sum_scores = sum([s for s in rec_scores.values()])\n",
    "        if sum_scores:\n",
    "            c = ITEM_TO_COUNTRY[items_views[0]]\n",
    "            rec_scores = {i: s / sum_scores  for i, s in rec_scores.items() }\n",
    "            \n",
    "        rec_scores = {i: s for i, s in rec_scores.items() if s > 0.05}\n",
    "        \n",
    "        # suma ambos scores\n",
    "        rec_scores = {i: model_rec_scores.get(i, 0) * WI + rec_scores.get(i, 0) * W0 + 0 if i in ITEM_TO_IDX else 0.2\\\n",
    "             for i in (rec_scores.keys() | model_rec_scores.keys()) if not i in BLACK_LIST }\n",
    "        \n",
    "        \n",
    "        rec = [item for item, score in heapq.nlargest(50, rec_scores.items(), key=lambda item: item[1])]\n",
    "\n",
    "        domains = set([ITEM_TO_DOMAIN[rec[i]] for i in range(3) if rec_scores[rec[i]] >= 1])\n",
    "        rec_fill = [r for r in rec if rec_scores[r]]\n",
    "\n",
    "        if domains:\n",
    "            rec = [r for r in rec if ITEM_TO_DOMAIN[r] in domains]\n",
    "            rec_fill = [r for r in rec_fill if r not in rec]\n",
    "\n",
    "        #pass\n",
    "        rec = rec[:10]\n",
    "        \n",
    "\n",
    "        # rellena en caso de no tener recomendaciones\n",
    "        if len(rec) < 10:\n",
    "            if len(rec):\n",
    "                fill_scores = {r: views_counter[r]  for domain_i in domains for r in most_viewed_by_domain.get(domain_i, [])}                \n",
    "                fill = [item for item, score in heapq.nlargest(10, fill_scores.items(), key=lambda item: item[1])]\n",
    "                if len(fill) < 10:\n",
    "                    fill += rec_fill\n",
    "            else: \n",
    "                fill = most_viewed_items\n",
    "            rec = fill_rec(rec, fill)\n",
    "        assert len(rec) == 10\n",
    "        \n",
    "        # evaluación\n",
    "        model_sum_dcg += dcg(rec, item_bought)\n",
    "        \n",
    "        rec_dom = ITEM_TO_DOMAIN[rec[0]]\n",
    "        tp_domain += ITEM_TO_DOMAIN[item_bought] in rec_dom\n",
    "        \n",
    "        n_recs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:  0.3186 (19998 recomendaciones)\n"
     ]
    }
   ],
   "source": [
    "print(f\"NDCG: {model_sum_dcg / (IDCG * n_recs): .4f} ({n_recs} recomendaciones)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (domain):  0.4176 (19998 recomendaciones)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy (domain): {tp_domain / n_recs: .4f} ({n_recs} recomendaciones)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y así se consigue el famoso Efecto Bolo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
