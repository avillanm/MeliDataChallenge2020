{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de filtrado colaborativo items to items\n",
    "\n",
    "### Summary\n",
    "En este notebook se exploró la estrategia de filtrado colaborativo items to items. Esta estrategia simple, tiene la ventaja de requerir poca capacidad de procesamiento, consiguiendo una buena relación entre performance y resultados, aunque quizá lo logre captar patrones más complejos.\n",
    "\n",
    "Se forman las siguientes asociaciones de productos a partir de las sesiones:\n",
    "* Asociación entre productos por visitas en una misma sesión\n",
    "* Asociación entre productos visitados y productos comprados.\n",
    "* Asociación entre términos de búsquedas y productos visitados.\n",
    "* Asociación entre términos de búsquedas y productos comprados.\n",
    "\n",
    "También se scorean los productos visitados con una función que toma en cuenta las posiciones de los page views del ítem en la sesión. Tomando la posición 1 a la más reciente a la la compra, el score se define como:\n",
    "\n",
    "\\begin{equation*}\n",
    "score(item_i) = \\sum_{pos}  \\frac{1}{log_{10}(pos + 1)}\n",
    "\\end{equation*}\n",
    "\n",
    "Solamente con esta estrategia de score de productos visitados, y utilizando como relleno los productos más vistos del dominio de la primera recomendación, se logra un **ndcg 0.2639** en test.\n",
    "\n",
    "Finalmente se pesan todos los scores de asociación consiguiendo un **ndcg 0.2889** en test y **0.2876** en submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lee del catatálogo los dominios de los productos (se usa en la evalaución)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = {}\n",
    "with open(\"./data/item_data.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        data = json.loads(line)\n",
    "        item_id = data.pop(\"item_id\")\n",
    "        data.pop(\"title\")\n",
    "        catalog[item_id] = data\n",
    "        # obtiene el país\n",
    "        catalog[item_id][\"country\"] = data[\"category_id\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_TO_DOMAIN = {}\n",
    "for item_id, item_info in catalog.items():\n",
    "    ITEM_TO_DOMAIN[item_id] = item_info[\"domain_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDCG = np.sum([(1 if i != 1 else 12) / np.log2(1 + i) for i in range(1, 11)])\n",
    "\n",
    "def dcg(rec, y_item_id, n=10):\n",
    "    y_domain = ITEM_TO_DOMAIN[y_item_id]\n",
    "    \n",
    "    return np.sum([(1 if yhat_item_id != y_item_id else 12) / np.log2(1 + i)\\\n",
    "                   for i, yhat_item_id in enumerate(rec[:n], 1)\\\n",
    "                  if (ITEM_TO_DOMAIN[yhat_item_id] == y_domain)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los productos sin precio o dominio se excluyen de las recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK_LIST = set()\n",
    "for item_id, item_info in catalog.items():\n",
    "    if (item_info[\"domain_id\"] == None) or (item_info[\"price\"] == None):\n",
    "        BLACK_LIST.add(item_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BLACK_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomendaciones Baseline\n",
    "Se usa como relleno (cold-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_viewed_items = Counter()\n",
    "most_sessions_items = Counter()\n",
    "most_bought_items = Counter()\n",
    "\n",
    "most_viewed_by_domain = {}\n",
    "\n",
    "line_idx = 0\n",
    "with open(\"./data/train_dataset-train_split.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        line_idx += 1\n",
    "        data = json.loads(line)\n",
    "        view = [event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"view\"]\n",
    "        most_viewed_items.update(view)\n",
    "        most_sessions_items.update(set(view))\n",
    "        most_bought_items[data[\"item_bought\"]] += 1\n",
    "        \n",
    "        for item_id in set(view):\n",
    "            domain = ITEM_TO_DOMAIN[item_id]\n",
    "            if not domain in most_viewed_by_domain:\n",
    "                most_viewed_by_domain[domain] = Counter()\n",
    "            most_viewed_by_domain[domain][item_id] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_viewed_items_br =[item_id for item_id, _ in\n",
    "    Counter({item_id: count for item_id, count\\\n",
    "             in most_viewed_items.items() if catalog[item_id][\"country\"] == \"B\" }).most_common(10)]\n",
    "\n",
    "most_viewed_items_mx  =[item_id for item_id, _ in\n",
    "    Counter({item_id: count for item_id, count\\\n",
    "             in most_viewed_items.items() if catalog[item_id][\"country\"] == \"M\" }).most_common(10)]\n",
    "\n",
    "most_viewed_items = [item for item, _ in most_viewed_items.most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_sessions_items_br =[item_id for item_id, _ in\n",
    "    Counter({item_id: count for item_id, count\\\n",
    "             in most_sessions_items.items() if catalog[item_id][\"country\"] == \"B\" }).most_common(10)]\n",
    "\n",
    "most_sessions_items_mx  =[item_id for item_id, _ in\n",
    "    Counter({item_id: count for item_id, count\\\n",
    "             in most_sessions_items.items() if catalog[item_id][\"country\"] == \"M\" }).most_common(10)]\n",
    "\n",
    "most_sessions_items = [item for item, _ in most_sessions_items.most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_bought_items_br =[item_id for item_id, _ in\n",
    "    Counter({item_id: count for item_id, count\\\n",
    "             in most_bought_items.items() if catalog[item_id][\"country\"] == \"B\" }).most_common(10)]\n",
    "\n",
    "most_bought_items_mx  =[item_id for item_id, _ in\n",
    "    Counter({item_id: count for item_id, count\\\n",
    "             in most_bought_items.items() if catalog[item_id][\"country\"] == \"M\" }).most_common(10)]\n",
    "\n",
    "most_bought_items = [item for item, _ in most_bought_items.most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain, counter in most_viewed_by_domain.items():\n",
    "    most_viewed_by_domain[domain] = [item for item, _ in counter.most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewed_count = 0\n",
    "n_recs = 0\n",
    "\n",
    "pop_view_sum_dcg = 0\n",
    "pop_session_sum_dcg = 0\n",
    "pop_bought_sum_dcg = 0\n",
    "\n",
    "\n",
    "country_pop_view_sum_dcg = 0\n",
    "country_pop_session_sum_dcg = 0\n",
    "country_pop_bought_sum_dcg = 0\n",
    "\n",
    "with open(\"./data/train_dataset-test_split.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        n_recs += 1 \n",
    "\n",
    "        data = json.loads(line)\n",
    "        item_bought = data[\"item_bought\"]\n",
    "        \n",
    "        pop_view_sum_dcg += dcg(most_viewed_items, item_bought)\n",
    "        pop_session_sum_dcg += dcg(most_sessions_items, item_bought)\n",
    "        pop_bought_sum_dcg += dcg(most_bought_items, item_bought)\n",
    "        \n",
    "        if catalog[item_bought][\"country\"] == \"B\":\n",
    "            country_pop_view_sum_dcg += dcg(most_viewed_items_br, item_bought)\n",
    "            country_pop_session_sum_dcg += dcg(most_sessions_items_br, item_bought)\n",
    "            country_pop_bought_sum_dcg += dcg(most_bought_items_br, item_bought)\n",
    "        elif catalog[item_bought][\"country\"] == \"M\":\n",
    "            country_pop_view_sum_dcg += dcg(most_viewed_items_mx, item_bought)\n",
    "            country_pop_session_sum_dcg += dcg(most_sessions_items_mx, item_bought)\n",
    "            country_pop_bought_sum_dcg += dcg(most_bought_items_mx, item_bought)\n",
    "        else:\n",
    "            raise(\"Error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG (top visitas) :  0.0106\n",
      "NDCG (top sesiones):  0.0106\n",
      "NDCG (top compras) :  0.0083\n"
     ]
    }
   ],
   "source": [
    "print(f\"NDCG (top visitas) : {pop_view_sum_dcg / (IDCG * n_recs): .4f}\")\n",
    "print(f\"NDCG (top sesiones): {pop_session_sum_dcg / (IDCG * n_recs): .4f}\")\n",
    "print(f\"NDCG (top compras) : {pop_bought_sum_dcg / (IDCG * n_recs): .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG (top visitas por país) :  0.0149\n",
      "NDCG (top sesiones por país):  0.0147\n",
      "NDCG (top compras por país) :  0.0118\n"
     ]
    }
   ],
   "source": [
    "print(f\"NDCG (top visitas por país) : {country_pop_view_sum_dcg / (IDCG * n_recs): .4f}\")\n",
    "print(f\"NDCG (top sesiones por país): {country_pop_session_sum_dcg / (IDCG * n_recs): .4f}\")\n",
    "print(f\"NDCG (top compras por país) : {country_pop_bought_sum_dcg / (IDCG * n_recs): .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_rec(rec, fill, n=10 ):\n",
    "    assert len(fill) >= n\n",
    "    fill_index = 0\n",
    "    while len(rec) < n:\n",
    "        if fill[fill_index] not in rec:\n",
    "            rec.append(fill[fill_index] )\n",
    "        fill_index += 1\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score sobre productos visitados\n",
    "\n",
    "Del análisis descriptivo se obtuvo que el 30% de los productos comprados fueron vistos en la sesión.\n",
    "\n",
    "Se analizan estrategias para rankear los productos visitados en la recomendación.\n",
    "\n",
    "* La mejor configuración fue contar las visitas pesando con la inversa del logaritmo de la posición, así más reciente mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:  0.2816 (1000 recomendaciones)\n",
      "NDCG:  0.2791 (2000 recomendaciones)\n",
      "NDCG:  0.2790 (3000 recomendaciones)\n",
      "NDCG:  0.2762 (4000 recomendaciones)\n",
      "NDCG:  0.2711 (5000 recomendaciones)\n",
      "NDCG:  0.2692 (6000 recomendaciones)\n",
      "NDCG:  0.2685 (7000 recomendaciones)\n",
      "NDCG:  0.2667 (8000 recomendaciones)\n",
      "NDCG:  0.2647 (9000 recomendaciones)\n",
      "NDCG:  0.2640 (10000 recomendaciones)\n",
      "NDCG:  0.2645 (11000 recomendaciones)\n",
      "NDCG:  0.2632 (12000 recomendaciones)\n",
      "NDCG:  0.2633 (13000 recomendaciones)\n",
      "NDCG:  0.2643 (14000 recomendaciones)\n",
      "NDCG:  0.2643 (15000 recomendaciones)\n",
      "NDCG:  0.2640 (16000 recomendaciones)\n",
      "NDCG:  0.2646 (17000 recomendaciones)\n",
      "NDCG:  0.2641 (18000 recomendaciones)\n",
      "NDCG:  0.2642 (19000 recomendaciones)\n",
      "NDCG:  0.2639 (20000 recomendaciones)\n"
     ]
    }
   ],
   "source": [
    "n_recs = 0\n",
    "sum_dcg = 0\n",
    "model_sum_dcg = 0\n",
    "\n",
    "with open(\"./data/train_dataset-test_split.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        n_recs += 1\n",
    "        # lee registro\n",
    "        data = json.loads(line)\n",
    "        item_bought = data[\"item_bought\"]\n",
    "        items_views = [event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"view\"]\n",
    "        \n",
    "        # Ranking de items visitados\n",
    "        items_pv_count = {}\n",
    "        items_views = items_views[::-1]            \n",
    "        for pos, item_view in enumerate(items_views, 1):\n",
    "            items_pv_count[item_view] = items_pv_count.get(item_view,0) + 1 / np.log10(pos + 1)\n",
    "        \n",
    "        rec_scores = defaultdict(dict)\n",
    "        # scores por visitas\n",
    "        for item_view, pv_count in items_pv_count.items():\n",
    "            # Asigna un score por item visitado\n",
    "            rec_scores[item_view] = rec_scores.get(item_view, 0) + pv_count \n",
    "        \n",
    "        \n",
    "        # equivalent to counter.most_common(10)\n",
    "        # https://stackoverflow.com/questions/29240807/python-collections-counter-most-common-complexity\n",
    "        rec = [item for item, _ in heapq.nlargest(10, rec_scores.items(), key=lambda item: item[1])]\n",
    "\n",
    "        # rellena en caso de no tener recomendaciones\n",
    "        if len(rec) < 10:\n",
    "            if len(rec):\n",
    "                country = catalog[rec[0]][\"country\"]\n",
    "                domain = ITEM_TO_DOMAIN[rec[0]]\n",
    "                fill = most_viewed_by_domain.get(domain, []) +\\\n",
    "                        (most_viewed_items_br if country == \"B\" else most_viewed_items_mx)\n",
    "            else: \n",
    "                fill = most_viewed_items\n",
    "            rec = fill_rec(rec, fill)\n",
    "            \n",
    "        # evaluación\n",
    "        model_sum_dcg += dcg(rec, item_bought)\n",
    "        \n",
    "        if (n_recs % 1000) == 0:\n",
    "            print(f\"NDCG: {model_sum_dcg / (IDCG * n_recs): .4f} ({n_recs} recomendaciones)\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG (i2i) :  0.2639\n"
     ]
    }
   ],
   "source": [
    "print(f\"NDCG (i2i) : {model_sum_dcg / (IDCG * n_recs): .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asociaciones entre productos visitados y comprados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejor configuración encontrada:\n",
    "\n",
    "* Tomar sesiones en el count de matriz\n",
    "* Normalizar count por el total de ventas del ítem vendido. Se aplica un smoothing la cantidad vendidos (suma 100 al denominador)\n",
    "* En la predicción se tiene en cuenta la cantidad de visitas y el orden de visita (más cercano mayor peso)\n",
    "* Se prioriza los visitados en la recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD == False:\n",
    "    user_idx = 0\n",
    "    view2bought = {}\n",
    "\n",
    "    counter_sessions = Counter()\n",
    "    counter_bought = Counter()\n",
    "\n",
    "    with open(\"./data/train_dataset-train_split.jl\", \"rt\") as fd:\n",
    "        for line in fd:\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            item_bought = data[\"item_bought\"]\n",
    "            country = catalog[item_bought][\"country\"]\n",
    "            items_views = set([event[\"event_info\"] for event in data[\"user_history\"]\\\n",
    "                   if event[\"event_type\"] == \"view\" and\\\n",
    "                   # exclude association in different countries\n",
    "                   country == catalog[event[\"event_info\"]][\"country\"]])\n",
    "\n",
    "            counter_bought[item_bought] += 1\n",
    "\n",
    "            items_pv_count = Counter(items_views)\n",
    "            for item_view, count in items_pv_count.items():\n",
    "\n",
    "                counter_sessions[item_view] += 1\n",
    "                if item_view in view2bought:\n",
    "                    view2bought[item_view][item_bought] += 1\n",
    "                else:\n",
    "                    counter = Counter()\n",
    "                    counter[item_bought] += 1\n",
    "                    view2bought[item_view] = counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD == False:\n",
    "    rows = []\n",
    "    for item_i, counter in view2bought.items():\n",
    "        for item_j, ses_count in counter.most_common():\n",
    "            rows.append((item_i, item_j, counter_sessions[item_i], counter_bought[item_j], ses_count))\n",
    "\n",
    "    df_bought_count = pd.DataFrame(rows, columns=(\"item_i\", \"item_j\", \"count_i\", \"count_j\", \"count_ij\"))\n",
    "\n",
    "    df_bought_count['item_i'] = df_bought_count.item_i.astype(np.uint32)\n",
    "    df_bought_count['item_j'] = df_bought_count.item_j.astype(np.uint32)\n",
    "\n",
    "    df_bought_count['count_i'] = df_bought_count.count_i.astype(np.uint16)\n",
    "    df_bought_count['count_j'] = df_bought_count.count_j.astype(np.uint16)\n",
    "    df_bought_count['count_ij'] = df_bought_count.count_ij.astype(np.uint16)\n",
    "\n",
    "    del rows\n",
    "\n",
    "    df_bought_count.to_pickle(\"./data/models/df_items_assosiation_bought_count.pkl\")\n",
    "else:\n",
    "    df_bought_count = pd.read_pickle(\"./data/models/df_items_assosiation_bought_count.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_i</th>\n",
       "      <th>item_j</th>\n",
       "      <th>count_i</th>\n",
       "      <th>count_j</th>\n",
       "      <th>count_ij</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1381888</td>\n",
       "      <td>1330214</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>361733</td>\n",
       "      <td>361733</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361733</td>\n",
       "      <td>1514607</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>361733</td>\n",
       "      <td>353783</td>\n",
       "      <td>200</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>361733</td>\n",
       "      <td>1680124</td>\n",
       "      <td>200</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_i   item_j  count_i  count_j  count_ij\n",
       "0  1381888  1330214        1        5         1\n",
       "1   361733   361733      200      200        72\n",
       "2   361733  1514607      200       20         6\n",
       "3   361733   353783      200       57         5\n",
       "4   361733  1680124      200       25         3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bought_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD == False:\n",
    "    import itertools\n",
    "    \n",
    "    min_freq = 2\n",
    "    counter_sessions = Counter()\n",
    "    with open(\"./data/train_dataset-train_split.jl\", \"rt\") as fd:\n",
    "        for line in fd:\n",
    "            data = json.loads(line)\n",
    "            item_bought = data[\"item_bought\"]\n",
    "            country = catalog[item_bought][\"country\"]\n",
    "            items_views = set([event[\"event_info\"] for event in data[\"user_history\"]\\\n",
    "                   if event[\"event_type\"] == \"view\" and\\\n",
    "                   # exclude association in different countries\n",
    "                   country == catalog[event[\"event_info\"]][\"country\"]])\n",
    "\n",
    "            counter_sessions.update(items_views)\n",
    "    item_set = set([k for k, v in counter_sessions.items() if  v >= min_freq])\n",
    "    \n",
    "    pair_items_counter = Counter()\n",
    "    counter_sessions = Counter()\n",
    "    with open(\"./data/train_dataset-train_split.jl\", \"rt\") as fd:\n",
    "        for line in fd:\n",
    "            data = json.loads(line)\n",
    "            items_views = set([event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"view\" and event[\"event_info\"] in item_set])\n",
    "\n",
    "            if len(items_views) > 1: \n",
    "                pair_items_counter.update(itertools.permutations(items_views, 2))\n",
    "                counter_sessions.update(items_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD == False:\n",
    "    rows = []\n",
    "    for (item_i, item_j), ses_count in pair_items_counter.items():\n",
    "        rows.append((item_i, item_j, counter_sessions[item_i], counter_sessions[item_j], ses_count))\n",
    "\n",
    "    df_association_views = pd.DataFrame(rows, columns=(\"item_i\", \"item_j\", \"count_i\", \"count_j\", \"count_ij\"))\n",
    "\n",
    "    df_association_views['item_i'] = df_association_views.item_i.astype(np.uint32)\n",
    "    df_association_views['item_j'] = df_association_views.item_j.astype(np.uint32)\n",
    "\n",
    "    df_association_views['count_i'] = df_association_views.count_i.astype(np.uint16)\n",
    "    df_association_views['count_j'] = df_association_views.count_j.astype(np.uint16)\n",
    "    df_association_views['count_ij'] = df_association_views.count_ij.astype(np.uint16)\n",
    "\n",
    "    del rows\n",
    "\n",
    "    df_association_views.to_pickle(\"./data/models/df_items_assosiation_views_count.pkl\")\n",
    "else:\n",
    "    df_association_views = pd.read_pickle(\"./data/models/df_items_assosiation_views_count.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_i</th>\n",
       "      <th>item_j</th>\n",
       "      <th>count_i</th>\n",
       "      <th>count_j</th>\n",
       "      <th>count_ij</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>361733</td>\n",
       "      <td>503045</td>\n",
       "      <td>185</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>361733</td>\n",
       "      <td>1831689</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361733</td>\n",
       "      <td>1174410</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>361733</td>\n",
       "      <td>1059724</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>361733</td>\n",
       "      <td>431884</td>\n",
       "      <td>185</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_i   item_j  count_i  count_j  count_ij\n",
       "0  361733   503045      185        7         1\n",
       "1  361733  1831689      185        1         1\n",
       "2  361733  1174410      185        2         1\n",
       "3  361733  1059724      185        2         1\n",
       "4  361733   431884      185        3         1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_association_views.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_i</th>\n",
       "      <th>item_j</th>\n",
       "      <th>count_i</th>\n",
       "      <th>count_j</th>\n",
       "      <th>count_ij</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1381888</td>\n",
       "      <td>1330214</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>361733</td>\n",
       "      <td>361733</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361733</td>\n",
       "      <td>1514607</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>361733</td>\n",
       "      <td>353783</td>\n",
       "      <td>200</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>361733</td>\n",
       "      <td>1680124</td>\n",
       "      <td>200</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_i   item_j  count_i  count_j  count_ij\n",
       "0  1381888  1330214        1        5         1\n",
       "1   361733   361733      200      200        72\n",
       "2   361733  1514607      200       20         6\n",
       "3   361733   353783      200       57         5\n",
       "4   361733  1680124      200       25         3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bought_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "item2item = defaultdict(dict)\n",
    "for row in df_association_views.itertuples():\n",
    "    item2item[row.item_i][row.item_j] = row.count_ij / (10 + row.count_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "view2bought = defaultdict(dict)\n",
    "for row in df_bought_count.itertuples():\n",
    "    view2bought[row.item_i][row.item_j] = row.count_ij  / (100 + row.count_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_association_views\n",
    "del df_bought_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:  0.3066 (1000 recomendaciones)\n",
      "NDCG:  0.3016 (2000 recomendaciones)\n",
      "NDCG:  0.3012 (3000 recomendaciones)\n",
      "NDCG:  0.2990 (4000 recomendaciones)\n",
      "NDCG:  0.2935 (5000 recomendaciones)\n",
      "NDCG:  0.2917 (6000 recomendaciones)\n",
      "NDCG:  0.2917 (7000 recomendaciones)\n",
      "NDCG:  0.2893 (8000 recomendaciones)\n",
      "NDCG:  0.2884 (9000 recomendaciones)\n",
      "NDCG:  0.2874 (10000 recomendaciones)\n",
      "NDCG:  0.2873 (11000 recomendaciones)\n",
      "NDCG:  0.2855 (12000 recomendaciones)\n",
      "NDCG:  0.2853 (13000 recomendaciones)\n",
      "NDCG:  0.2867 (14000 recomendaciones)\n",
      "NDCG:  0.2864 (15000 recomendaciones)\n",
      "NDCG:  0.2862 (16000 recomendaciones)\n",
      "NDCG:  0.2866 (17000 recomendaciones)\n",
      "NDCG:  0.2857 (18000 recomendaciones)\n",
      "NDCG:  0.2856 (19000 recomendaciones)\n",
      "NDCG:  0.2851 (20000 recomendaciones)\n"
     ]
    }
   ],
   "source": [
    "n_recs = 0\n",
    "sum_dcg = 0\n",
    "model_sum_dcg = 0\n",
    "\n",
    "W0 = 1\n",
    "W1 = 1\n",
    "W3 = 3\n",
    "\n",
    "with open(\"./data/train_dataset-test_split.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        n_recs += 1\n",
    "        # lee registro\n",
    "        data = json.loads(line)\n",
    "        item_bought = data[\"item_bought\"]\n",
    "        items_views = [event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"view\"]\n",
    "\n",
    "        # Ranking de items visitados\n",
    "        items_pv_count = {}\n",
    "        items_views = items_views[::-1]            \n",
    "        for pos, item_view in enumerate(items_views, 1):\n",
    "            items_pv_count[item_view] = items_pv_count.get(item_view,0) + 1 / np.log10(pos + 1) \n",
    "        \n",
    "            \n",
    "        # recomendaciones por modelo\n",
    "        rec_scores = {}\n",
    "        for item_view, pv_count in items_pv_count.items():\n",
    "            \n",
    "            # Asigna un score por item visitado\n",
    "            rec_scores[item_view] = rec_scores.get(item_view, 0) + np.log10(pv_count + 1) * W0 \n",
    "            \n",
    "            # Asigna scores por asociaciones de visitas\n",
    "            if item_view in item2item:\n",
    "                item_scores = item2item[item_view]\n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * W1 \\\n",
    "                                   for key in item_scores.keys()})\n",
    "                \n",
    "            # Asigna scores por de compras\n",
    "            if item_view in view2bought:\n",
    "                item_scores = view2bought[item_view]\n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * pv_count * W3 \\\n",
    "                                   for key in item_scores.keys()})\n",
    "                \n",
    "        # exclude items from black List\n",
    "        rec_scores = {k: v for k, v in rec_scores.items() if k not in BLACK_LIST}\n",
    "        \n",
    "        # equivalent to counter.most_common(10)\n",
    "        # https://stackoverflow.com/questions/29240807/python-collections-counter-most-common-complexity\n",
    "        rec = [item for item, _ in heapq.nlargest(10, rec_scores.items(), key=lambda item: item[1])]\n",
    "\n",
    "        # rellena en caso de no tener recomendaciones\n",
    "        if len(rec) < 10:\n",
    "            if len(rec):\n",
    "                domain = ITEM_TO_DOMAIN[rec[0]]\n",
    "                fill = most_viewed_by_domain.get(domain, []) + most_viewed_items\n",
    "            else:\n",
    "                fill = most_viewed_items\n",
    "\n",
    "            rec = fill_rec(rec, fill)\n",
    "            \n",
    "        # evaluación\n",
    "        model_sum_dcg += dcg(rec, item_bought)\n",
    "        \n",
    "        if (n_recs % 1000) == 0:\n",
    "            print(f\"NDCG: {model_sum_dcg / (IDCG * n_recs): .4f} ({n_recs} recomendaciones)\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG (i2i) :  0.2851\n"
     ]
    }
   ],
   "source": [
    "print(f\"NDCG (i2i) : {model_sum_dcg / (IDCG * n_recs): .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asociaciones con search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contador de sesiones por busqueda y tokens\n",
    "# También cuenta el df de token tomando como documentos los textos de búsquedas\n",
    "if LOAD == False:\n",
    "    counter_searchs = Counter()\n",
    "    token_sessions = Counter()\n",
    "    counter_bought = Counter()\n",
    "    with open(\"./data/train_dataset-train_split.jl\", \"rt\") as fd:\n",
    "        for line in fd:\n",
    "            data = json.loads(line)\n",
    "            searchs = set([event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"search\"])\n",
    "            item_bought = data[\"item_bought\"]\n",
    "            counter_searchs.update(searchs)\n",
    "            counter_bought[item_bought] +=1\n",
    "\n",
    "    token_df = Counter()\n",
    "    for text in counter_searchs.keys():\n",
    "        token_df.update(set(text.split()))\n",
    "\n",
    "    token_sessions = Counter()\n",
    "    for text, ses_count in counter_searchs.items():\n",
    "        for token in set(text.split()):\n",
    "            token_sessions[token] += ses_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contador de asociaciones de tokens de búsquedas con productos comprados\n",
    "if LOAD == False:\n",
    "    token2bought = {}\n",
    "    with open(\"./data/train_dataset-train_split.jl\", \"rt\") as fd:\n",
    "        for line in fd:\n",
    "            data = json.loads(line)\n",
    "            searchs = set([event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"search\"])\n",
    "            item_bought = data[\"item_bought\"]\n",
    "            for text in searchs:\n",
    "                for token in text.split():\n",
    "                    if token in token2bought:\n",
    "                        token2bought[token][item_bought] += 1\n",
    "                    else:\n",
    "                        counter = Counter()\n",
    "                        counter[item_bought] += 1\n",
    "                        token2bought[token] = counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contador de asocaciones de busquedas con productos comprados\n",
    "if LOAD == False:\n",
    "    searchset = set([search for search, c in counter_searchs.items() if c > 1])\n",
    "    searchbought = {}\n",
    "    with open(\"./data/train_dataset-train_split.jl\", \"rt\") as fd:\n",
    "        for line in fd:\n",
    "            data = json.loads(line)\n",
    "            searchs = set([event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"search\" and event[\"event_info\"] in searchset])\n",
    "            item_bought = data[\"item_bought\"]\n",
    "            for search in searchs:\n",
    "                if search in searchbought:\n",
    "                    searchbought[search][item_bought] += 1\n",
    "                else:\n",
    "                    counter = Counter()\n",
    "                    counter[item_bought] += 1\n",
    "                    searchbought[search] = counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contador de asociación entre busqueda y visitas\n",
    "\n",
    "# se toma visitas posteriores a la búsqueda y previas de siguiente búsqueda\n",
    "if LOAD == False:\n",
    "    search2views = {}\n",
    "    with open(\"./data/train_dataset-train_split.jl\", \"rt\") as fd:\n",
    "        for line in fd:\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            events = data[\"user_history\"] \n",
    "            last_search = None\n",
    "            search_itemset = {}\n",
    "            for event in events:\n",
    "                if event[\"event_type\"] == \"search\":\n",
    "                    last_search = event[\"event_info\"]\n",
    "                elif last_search:\n",
    "                    if last_search in search_itemset:\n",
    "                        search_itemset[last_search].add(event[\"event_info\"])\n",
    "                    else:\n",
    "                        search_itemset[last_search] = set([event[\"event_info\"]])\n",
    "\n",
    "            for search, itemset in search_itemset.items():\n",
    "                if search in search2views:\n",
    "                    search2views[search].update(itemset)\n",
    "                else:\n",
    "                    search2views[search] = Counter(itemset)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD == False:\n",
    "    # contador de productos vistos luego de búsquedas\n",
    "    counter_views_insearch = Counter()\n",
    "    for counter in search2views.values():\n",
    "        counter_views_insearch.update(dict(counter.items()))\n",
    "        \n",
    "    # Contador de asociación entre tokens y visitas\n",
    "    token2views = {}\n",
    "    for search, item_counter in search2views.items():\n",
    "        for token in search.split():\n",
    "            if token in token2views:\n",
    "                token2views[token].update(dict(item_counter.items()))\n",
    "            else:\n",
    "                token2views[token] = Counter(dict(item_counter.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \"Texto Búsqueda\" -> \"Productos comprados\"\n",
    "if LOAD == False:\n",
    "    rows = []\n",
    "    for search, items_count  in searchbought.items():\n",
    "        for item, ses_count, in items_count.items():\n",
    "            rows.append((search, item, counter_searchs[search], counter_bought[item], ses_count))\n",
    "\n",
    "    df_search_bought = pd.DataFrame(rows, columns=(\"search\", \"item\", \"count_s\", \"count_i\", \"count_si\"))\n",
    "\n",
    "    df_search_bought['item'] = df_search_bought.item.astype(np.uint32)\n",
    "\n",
    "    df_search_bought['count_i'] = df_search_bought.count_i.astype(np.uint16)\n",
    "    df_search_bought['count_s'] = df_search_bought.count_s.astype(np.uint16)\n",
    "    df_search_bought['count_si'] = df_search_bought.count_si.astype(np.uint16)\n",
    "\n",
    "    del rows\n",
    "\n",
    "    df_search_bought.to_pickle(\"./data/models/df_assosiation_search_text_bought.pkl\")\n",
    "else:\n",
    "    df_search_bought = pd.read_pickle(\"./data/models/df_assosiation_search_text_bought.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search</th>\n",
       "      <th>item</th>\n",
       "      <th>count_s</th>\n",
       "      <th>count_i</th>\n",
       "      <th>count_si</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAQUINA CORTAR CABELO BARBA</td>\n",
       "      <td>1330214</td>\n",
       "      <td>195</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAQUINA CORTAR CABELO BARBA</td>\n",
       "      <td>1086760</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAQUINA CORTAR CABELO BARBA</td>\n",
       "      <td>1514059</td>\n",
       "      <td>195</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAQUINA CORTAR CABELO BARBA</td>\n",
       "      <td>1761121</td>\n",
       "      <td>195</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAQUINA CORTAR CABELO BARBA</td>\n",
       "      <td>636487</td>\n",
       "      <td>195</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        search     item  count_s  count_i  count_si\n",
       "0  MAQUINA CORTAR CABELO BARBA  1330214      195        5         1\n",
       "1  MAQUINA CORTAR CABELO BARBA  1086760      195        1         1\n",
       "2  MAQUINA CORTAR CABELO BARBA  1514059      195       12         1\n",
       "3  MAQUINA CORTAR CABELO BARBA  1761121      195       37         5\n",
       "4  MAQUINA CORTAR CABELO BARBA   636487      195       41         1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_search_bought.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \"Tokens búsquedas\" -> \"Productos comprados\"\n",
    "if LOAD == False:\n",
    "    rows = []\n",
    "    for token, items_count  in token2bought.items():\n",
    "        for item, ses_count, in items_count.items():\n",
    "            rows.append((token, item, token_sessions[token], counter_bought[item], ses_count))\n",
    "\n",
    "    df_search_token_bought = pd.DataFrame(rows, columns=(\"token\", \"item\", \"count_t\", \"count_i\", \"count_ti\"))\n",
    "\n",
    "    df_search_token_bought['item'] = df_search_token_bought.item.astype(np.uint32)\n",
    "\n",
    "    df_search_token_bought['count_i'] = df_search_token_bought.count_i.astype(np.uint16)\n",
    "    df_search_token_bought['count_t'] = df_search_token_bought.count_t.astype(np.uint16)\n",
    "    df_search_token_bought['count_ti'] = df_search_token_bought.count_ti.astype(np.uint16)\n",
    "\n",
    "    del rows\n",
    "\n",
    "    df_search_token_bought.to_pickle(\"./data/models/df_assosiation_search_token_bought.pkl\")\n",
    "else:\n",
    "    df_search_token_bought = pd.read_pickle(\"./data/models/df_assosiation_search_token_bought.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>item</th>\n",
       "      <th>count_t</th>\n",
       "      <th>count_i</th>\n",
       "      <th>count_ti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOCHILA</td>\n",
       "      <td>1330214</td>\n",
       "      <td>5637</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOCHILA</td>\n",
       "      <td>1324879</td>\n",
       "      <td>5637</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MOCHILA</td>\n",
       "      <td>528769</td>\n",
       "      <td>5637</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOCHILA</td>\n",
       "      <td>804644</td>\n",
       "      <td>5637</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MOCHILA</td>\n",
       "      <td>1423562</td>\n",
       "      <td>5637</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token     item  count_t  count_i  count_ti\n",
       "0  MOCHILA  1330214     5637        5         4\n",
       "1  MOCHILA  1324879     5637       30         1\n",
       "2  MOCHILA   528769     5637       25         1\n",
       "3  MOCHILA   804644     5637       23         1\n",
       "4  MOCHILA  1423562     5637        9         1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_search_token_bought.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \"Texto Búsqueda\" -> \"Productos visitados\"\n",
    "if LOAD == False:\n",
    "    rows = []\n",
    "    for search, items_count  in search2views.items():\n",
    "        for item, ses_count, in items_count.items():\n",
    "            rows.append((search, item, counter_searchs[search], counter_views_insearch[item], ses_count))\n",
    "\n",
    "    df_search_views = pd.DataFrame(rows, columns=(\"search\", \"item\", \"count_s\", \"count_i\", \"count_si\"))\n",
    "\n",
    "    df_search_views['item'] = df_search_views.item.astype(np.uint32)\n",
    "\n",
    "    df_search_views['count_i'] = df_search_views.count_i.astype(np.uint16)\n",
    "    df_search_views['count_s'] = df_search_views.count_s.astype(np.uint16)\n",
    "    df_search_views['count_si'] = df_search_views.count_si.astype(np.uint16)\n",
    "\n",
    "    del rows\n",
    "\n",
    "    df_search_views.to_pickle(\"./data/models/df_assosiation_search_text_views.pkl\")\n",
    "else:\n",
    "    df_search_views = pd.read_pickle(\"./mei_challenger/data/models/df_assosiation_search_text_views.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search</th>\n",
       "      <th>item</th>\n",
       "      <th>count_s</th>\n",
       "      <th>count_i</th>\n",
       "      <th>count_si</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAQUINA CORTAR CABELO BARBA</td>\n",
       "      <td>1381888</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAQUINA CORTAR CABELO BARBA</td>\n",
       "      <td>361733</td>\n",
       "      <td>195</td>\n",
       "      <td>214</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAQUINA CORTAR CABELO BARBA</td>\n",
       "      <td>1831689</td>\n",
       "      <td>195</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAQUINA CORTAR CABELO BARBA</td>\n",
       "      <td>1174410</td>\n",
       "      <td>195</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAQUINA CORTAR CABELO BARBA</td>\n",
       "      <td>1059724</td>\n",
       "      <td>195</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        search     item  count_s  count_i  count_si\n",
       "0  MAQUINA CORTAR CABELO BARBA  1381888      195        1         1\n",
       "1  MAQUINA CORTAR CABELO BARBA   361733      195      214        54\n",
       "2  MAQUINA CORTAR CABELO BARBA  1831689      195        2         1\n",
       "3  MAQUINA CORTAR CABELO BARBA  1174410      195        2         1\n",
       "4  MAQUINA CORTAR CABELO BARBA  1059724      195        2         1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_search_views.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \"Tokens búsquedas\" -> \"Productos Visitados\"\n",
    "if LOAD == False:\n",
    "    rows = []\n",
    "    for token, items_count  in token2views.items():\n",
    "        for item, ses_count, in items_count.items():\n",
    "            rows.append((token, item, token_sessions[token], counter_views_insearch[item], ses_count))\n",
    "\n",
    "    df_search_token_views = pd.DataFrame(rows, columns=(\"token\", \"item\", \"count_t\", \"count_i\", \"count_ti\"))\n",
    "\n",
    "    df_search_token_views['item'] = df_search_token_views.item.astype(np.uint32)\n",
    "\n",
    "    df_search_token_views['count_i'] = df_search_token_views.count_i.astype(np.uint16)\n",
    "    df_search_token_views['count_t'] = df_search_token_views.count_t.astype(np.uint16)\n",
    "    df_search_token_views['count_ti'] = df_search_token_views.count_ti.astype(np.uint16)\n",
    "\n",
    "    del rows\n",
    "\n",
    "    df_search_token_views.to_pickle(\"./data/models/df_assosiation_search_token_views.pkl\")\n",
    "else:\n",
    "    df_search_token_views = pd.read_pickle(\"./data/models/df_assosiation_search_token_views.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>item</th>\n",
       "      <th>count_t</th>\n",
       "      <th>count_i</th>\n",
       "      <th>count_ti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAQUINA</td>\n",
       "      <td>1381888</td>\n",
       "      <td>11668</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAQUINA</td>\n",
       "      <td>361733</td>\n",
       "      <td>11668</td>\n",
       "      <td>214</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAQUINA</td>\n",
       "      <td>1831689</td>\n",
       "      <td>11668</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAQUINA</td>\n",
       "      <td>1174410</td>\n",
       "      <td>11668</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAQUINA</td>\n",
       "      <td>1059724</td>\n",
       "      <td>11668</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token     item  count_t  count_i  count_ti\n",
       "0  MAQUINA  1381888    11668        1         1\n",
       "1  MAQUINA   361733    11668      214       142\n",
       "2  MAQUINA  1831689    11668        2         1\n",
       "3  MAQUINA  1174410    11668        2         1\n",
       "4  MAQUINA  1059724    11668        2         2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_search_token_views.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "token2bought = defaultdict(dict)\n",
    "for row in df_search_token_bought.itertuples():\n",
    "    token2bought[row.token][row.item] = (row.count_ti )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "token2view = defaultdict(dict)\n",
    "for row in df_search_token_views.itertuples():\n",
    "    token2view[row.token][row.item] = (row.count_ti )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "text2bought = defaultdict(dict)\n",
    "for row in df_search_bought.itertuples():\n",
    "    text2bought[row.search][row.item] = (row.count_si ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "text2view = defaultdict(dict)\n",
    "for row in df_search_views.itertuples():\n",
    "    text2view[row.search][row.item] = (row.count_si ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_search_views\n",
    "del df_search_token_bought\n",
    "del df_search_token_views\n",
    "del df_search_bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se queda con el top para optimizar consultas\n",
    "n = 128\n",
    "for text in text2view.keys():\n",
    "    text2view[text] = {item: score for item, score in heapq.nlargest(n, text2view[text].items(), key=lambda item: item[1])}\n",
    "    \n",
    "for token in token2view.keys():\n",
    "    token2view[token] = {item: score for item, score in heapq.nlargest(n, token2view[token].items(), key=lambda item: item[1])}\n",
    "    \n",
    "n = 256\n",
    "for text in text2bought.keys():\n",
    "    text2bought[text] = {item: score for item, score in heapq.nlargest(n, text2bought[text].items(), key=lambda item: item[1])}\n",
    "    \n",
    "for token in token2bought.keys():\n",
    "    token2bought[token] = {item: score for item, score in heapq.nlargest(n, token2bought[token].items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_searchs = Counter()\n",
    "with open(\"./data/train_dataset-train_split.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        data = json.loads(line)\n",
    "        searchs = set([event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"search\"])\n",
    "        counter_searchs.update(searchs)\n",
    "\n",
    "token_df = Counter()\n",
    "for text in counter_searchs.keys():\n",
    "    token_df.update(set(text.split()))\n",
    "del counter_searchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:  0.1314 (1000 recomendaciones)\n",
      "NDCG:  0.1303 (2000 recomendaciones)\n",
      "NDCG:  0.1280 (3000 recomendaciones)\n",
      "NDCG:  0.1269 (4000 recomendaciones)\n",
      "NDCG:  0.1251 (5000 recomendaciones)\n",
      "NDCG:  0.1229 (6000 recomendaciones)\n",
      "NDCG:  0.1234 (7000 recomendaciones)\n",
      "NDCG:  0.1216 (8000 recomendaciones)\n",
      "NDCG:  0.1216 (9000 recomendaciones)\n",
      "NDCG:  0.1216 (10000 recomendaciones)\n",
      "NDCG:  0.1198 (11000 recomendaciones)\n",
      "NDCG:  0.1201 (12000 recomendaciones)\n",
      "NDCG:  0.1194 (13000 recomendaciones)\n",
      "NDCG:  0.1198 (14000 recomendaciones)\n",
      "NDCG:  0.1201 (15000 recomendaciones)\n",
      "NDCG:  0.1200 (16000 recomendaciones)\n",
      "NDCG:  0.1204 (17000 recomendaciones)\n",
      "NDCG:  0.1199 (18000 recomendaciones)\n",
      "NDCG:  0.1200 (19000 recomendaciones)\n",
      "NDCG:  0.1197 (20000 recomendaciones)\n"
     ]
    }
   ],
   "source": [
    "n_recs = 0\n",
    "sum_dcg = 0\n",
    "model_sum_dcg = 0\n",
    "\n",
    "Wb = 1\n",
    "Wv = 1\n",
    "with open(\"./data/train_dataset-test_split.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        n_recs += 1\n",
    "        # lee registro\n",
    "        data = json.loads(line)\n",
    "        item_bought = data[\"item_bought\"]\n",
    "        searchs = [event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"search\"]\n",
    "        \n",
    "\n",
    "        # Ranking de palabras de búsqueda\n",
    "        tf_counter = {}\n",
    "        text_counter = {}\n",
    "        searchs = searchs[::-1]            \n",
    "        for pos, text in enumerate(searchs, 1):\n",
    "            text_counter[text] = tf_counter.get(text, 0) + 1 / np.log10(pos + 1)\n",
    "            for token in text.split():\n",
    "                tf_counter[token] = tf_counter.get(token, 0) + 1 / np.log10(pos + 1)\n",
    "            \n",
    "        # recomendaciones por modelo\n",
    "        rec_scores = {}\n",
    "        \n",
    "        for text, tf in text_counter.items():\n",
    "            if text in text2bought:\n",
    "                item_scores = text2bought[text] \n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * tf * Wb\\\n",
    "                                  for key in item_scores.keys()})\n",
    "        if text in  text2view:\n",
    "            for text, tf in text_counter.items():\n",
    "                item_scores = text2view[text] \n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * tf * Wv\\\n",
    "                                  for key in item_scores.keys()})\n",
    "            \n",
    "        for token, tf in tf_counter.items():\n",
    "            if len(token) < 2:\n",
    "                continue\n",
    "            if token in token2bought:\n",
    "                item_scores = token2bought[token] \n",
    "                tfidf =  tf  / token_df[token]\n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * tfidf * Wb\\\n",
    "                                  for key in item_scores.keys()})\n",
    "            if token in token2view:\n",
    "                item_scores = token2view[token] \n",
    "                tfidf =  tf  / token_df[token]\n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * tfidf * Wv\\\n",
    "                                  for key in item_scores.keys()})\n",
    "        if rec_scores:\n",
    "            country_rec = catalog[max(rec_scores, key=rec_scores.get)][\"country\"]\n",
    "            rec_scores = {k: v for k,v in rec_scores.items() if catalog[k][\"country\"] == country_rec}\n",
    "         \n",
    "        \n",
    "        # equivalent to counter.most_common(10)\n",
    "        # https://stackoverflow.com/questions/29240807/python-collections-counter-most-common-complexity\n",
    "        rec = [item for item, _ in heapq.nlargest(10, rec_scores.items(), key=lambda item: item[1])]\n",
    "\n",
    "        # rellena en caso de no tener recomendaciones\n",
    "        if len(rec) < 10:\n",
    "            if len(rec):\n",
    "                domain = ITEM_TO_DOMAIN[rec[0]]\n",
    "                fill = most_viewed_by_domain.get(domain, []) + most_viewed_items\n",
    "            else:\n",
    "                fill = most_viewed_items\n",
    "\n",
    "            rec = fill_rec(rec, fill)\n",
    "            \n",
    "        # evaluación\n",
    "        model_sum_dcg += dcg(rec, item_bought)\n",
    "        \n",
    "        if (n_recs % 1000) == 0:\n",
    "            print(f\"NDCG: {model_sum_dcg / (IDCG * n_recs): .4f} ({n_recs} recomendaciones)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG (i2i) :  0.1198\n"
     ]
    }
   ],
   "source": [
    "print(f\"NDCG (i2i) : {model_sum_dcg / (IDCG * n_recs): .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Final: Se toman todas las asociaciones\n",
    "\n",
    "Se ensamblan todas las asociaciones usando pesos en los scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:  0.3094 (1000 recomendaciones)\n",
      "NDCG:  0.3065 (2000 recomendaciones)\n",
      "NDCG:  0.3057 (3000 recomendaciones)\n",
      "NDCG:  0.3041 (4000 recomendaciones)\n",
      "NDCG:  0.2982 (5000 recomendaciones)\n",
      "NDCG:  0.2962 (6000 recomendaciones)\n",
      "NDCG:  0.2962 (7000 recomendaciones)\n",
      "NDCG:  0.2938 (8000 recomendaciones)\n",
      "NDCG:  0.2926 (9000 recomendaciones)\n",
      "NDCG:  0.2917 (10000 recomendaciones)\n",
      "NDCG:  0.2914 (11000 recomendaciones)\n",
      "NDCG:  0.2894 (12000 recomendaciones)\n",
      "NDCG:  0.2892 (13000 recomendaciones)\n",
      "NDCG:  0.2906 (14000 recomendaciones)\n",
      "NDCG:  0.2904 (15000 recomendaciones)\n",
      "NDCG:  0.2903 (16000 recomendaciones)\n",
      "NDCG:  0.2905 (17000 recomendaciones)\n",
      "NDCG:  0.2896 (18000 recomendaciones)\n",
      "NDCG:  0.2895 (19000 recomendaciones)\n",
      "NDCG:  0.2889 (20000 recomendaciones)\n"
     ]
    }
   ],
   "source": [
    "n_recs = 0\n",
    "sum_dcg = 0\n",
    "model_sum_dcg = 0\n",
    "\n",
    "W0 = 100 # ítems visitados en sesión\n",
    "W1 = 100 # asociación con visitas\n",
    "W3 = 300 # asociación con compras\n",
    "W4 = 0.001 # asociación con búsquedas\n",
    "\n",
    "fills_count = 0\n",
    "with open(\"./data/train_dataset-test_split.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        n_recs += 1\n",
    "        # lee registro\n",
    "        data = json.loads(line)\n",
    "        item_bought = data[\"item_bought\"]\n",
    "        items_views = [event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"view\"]\n",
    "        searchs = [event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"search\"]\n",
    "\n",
    "        # Ranking de items visitados\n",
    "        items_pv_count = {}\n",
    "        items_views = items_views[::-1]            \n",
    "        for pos, item_view in enumerate(items_views, 1):\n",
    "            items_pv_count[item_view] = items_pv_count.get(item_view,0) + 1 / np.log10(pos + 1) \n",
    "        \n",
    "            \n",
    "        # recomendaciones por modelo\n",
    "        rec_scores = {}\n",
    "        for item_view, pv_count in items_pv_count.items():\n",
    "            \n",
    "            # Asigna un score por item visitado\n",
    "            rec_scores[item_view] = rec_scores.get(item_view, 0) + np.log10(pv_count + 1) * W0 \n",
    "            \n",
    "            # Asigna scores por asociaciones de visitas\n",
    "            if item_view in item2item:\n",
    "                item_scores = item2item[item_view]\n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * W1 \\\n",
    "                                   for key in item_scores.keys()})\n",
    "                \n",
    "            # Asigna scores por de compras\n",
    "            if item_view in view2bought:\n",
    "                item_scores = view2bought[item_view]\n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * pv_count * W3 \\\n",
    "                                   for key in item_scores.keys()})\n",
    "                \n",
    "        \n",
    "        # Ranking de palabras de búsqueda\n",
    "        tf_counter = {}\n",
    "        text_counter = {}\n",
    "        searchs = searchs[::-1]            \n",
    "        for pos, text in enumerate(searchs, 1):\n",
    "            text_counter[text] = tf_counter.get(text, 0) + 1 / np.log10(pos + 1)\n",
    "            for token in text.split():\n",
    "                tf_counter[token] = tf_counter.get(token, 0) + 1 / np.log10(pos + 1)\n",
    "\n",
    "        for text, tf in text_counter.items():\n",
    "            if text in text2bought:\n",
    "                item_scores = text2bought[text] \n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * tf * W4\\\n",
    "                                  for key in item_scores.keys()})\n",
    "        if text in  text2view:\n",
    "            for text, tf in text_counter.items():\n",
    "                item_scores = text2view[text] \n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * tf * W4\\\n",
    "                                  for key in item_scores.keys()})\n",
    "\n",
    "        for token, tf in tf_counter.items():\n",
    "            if len(token) < 2:\n",
    "                continue\n",
    "            if token in token2bought:\n",
    "                item_scores = token2bought[token] \n",
    "                tfidf =  tf  / token_df[token]\n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * tfidf * W4\\\n",
    "                                  for key in item_scores.keys()})\n",
    "            if token in token2view:\n",
    "                item_scores = token2view[token] \n",
    "                tfidf =  tf  / token_df[token]\n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * tfidf * W4\\\n",
    "                                  for key in item_scores.keys()})\n",
    "        if rec_scores:\n",
    "            country_rec = catalog[max(rec_scores, key=rec_scores.get)][\"country\"]\n",
    "            rec_scores = {k: v for k,v in rec_scores.items() if catalog[k][\"country\"] == country_rec}\n",
    "            # exclude items from black List\n",
    "            rec_scores = {k: v for k, v in rec_scores.items() if k not in BLACK_LIST}\n",
    "        \n",
    "        # equivalent to counter.most_common(10)\n",
    "        # https://stackoverflow.com/questions/29240807/python-collections-counter-most-common-complexity\n",
    "        rec = [item for item, _ in heapq.nlargest(10, rec_scores.items(), key=lambda item: item[1])]\n",
    "\n",
    "        \n",
    "         # rellena en caso de no tener recomendaciones suficientes\n",
    "        if len(rec) < 10:\n",
    "            if len(rec):\n",
    "                domain = ITEM_TO_DOMAIN[rec[0]]\n",
    "                fill = most_viewed_by_domain.get(domain, []) +\\\n",
    "                        (most_viewed_items_br if country_rec == \"B\" else most_viewed_items_mx)\n",
    "            else: \n",
    "                fill = most_viewed_items\n",
    "            rec = fill_rec(rec, fill)\n",
    "            \n",
    "        # evaluación\n",
    "        model_sum_dcg += dcg(rec, item_bought)\n",
    "        \n",
    "        if (n_recs % 1000) == 0:\n",
    "            print(f\"NDCG: {model_sum_dcg / (IDCG * n_recs): .4f} ({n_recs} recomendaciones)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG (i2i) :  0.2889\n"
     ]
    }
   ],
   "source": [
    "print(f\"NDCG (i2i) : {model_sum_dcg / (IDCG * n_recs): .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalualción de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:  0.2815 (1000 recomendaciones)\n",
      "NDCG:  0.2805 (2000 recomendaciones)\n",
      "NDCG:  0.2816 (3000 recomendaciones)\n",
      "NDCG:  0.2828 (4000 recomendaciones)\n",
      "NDCG:  0.2856 (5000 recomendaciones)\n",
      "NDCG:  0.2873 (6000 recomendaciones)\n",
      "NDCG:  0.2890 (7000 recomendaciones)\n",
      "NDCG:  0.2866 (8000 recomendaciones)\n",
      "NDCG:  0.2867 (9000 recomendaciones)\n",
      "NDCG:  0.2872 (10000 recomendaciones)\n",
      "NDCG:  0.2882 (11000 recomendaciones)\n",
      "NDCG:  0.2892 (12000 recomendaciones)\n",
      "NDCG:  0.2889 (13000 recomendaciones)\n",
      "NDCG:  0.2880 (14000 recomendaciones)\n",
      "NDCG:  0.2882 (15000 recomendaciones)\n",
      "NDCG:  0.2881 (16000 recomendaciones)\n",
      "NDCG:  0.2885 (17000 recomendaciones)\n",
      "NDCG:  0.2877 (18000 recomendaciones)\n",
      "NDCG:  0.2885 (19000 recomendaciones)\n"
     ]
    }
   ],
   "source": [
    "n_recs = 0\n",
    "sum_dcg = 0\n",
    "model_sum_dcg = 0\n",
    "\n",
    "W0 = 100\n",
    "W1 = 100\n",
    "W3 = 300\n",
    "W4 = 0.001\n",
    "\n",
    "with open(\"./data/train_dataset-val_split.jl\", \"rt\") as fd:\n",
    "    for line in fd:\n",
    "        n_recs += 1\n",
    "        # lee registro\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "        except:\n",
    "            continue\n",
    "        item_bought = data[\"item_bought\"]\n",
    "        items_views = [event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"view\"]\n",
    "        searchs = [event[\"event_info\"] for event in data[\"user_history\"] if event[\"event_type\"] == \"search\"]\n",
    "\n",
    "        # Ranking de items visitados\n",
    "        items_pv_count = {}\n",
    "        items_views = items_views[::-1]            \n",
    "        for pos, item_view in enumerate(items_views, 1):\n",
    "            items_pv_count[item_view] = items_pv_count.get(item_view,0) + 1 / np.log10(pos + 1) \n",
    "        \n",
    "            \n",
    "        # recomendaciones por modelo\n",
    "        rec_scores = {}\n",
    "        for item_view, pv_count in items_pv_count.items():\n",
    "            \n",
    "            # Asigna un score por item visitado\n",
    "            rec_scores[item_view] = rec_scores.get(item_view, 0) + np.log10(pv_count + 1) * W0 \n",
    "            \n",
    "            # Asigna scores por asociaciones de visitas\n",
    "            if item_view in item2item:\n",
    "                item_scores = item2item[item_view]\n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * W1 \\\n",
    "                                   for key in item_scores.keys()})\n",
    "                \n",
    "            # Asigna scores por de compras\n",
    "            if item_view in view2bought:\n",
    "                item_scores = view2bought[item_view]\n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * pv_count * W3 \\\n",
    "                                   for key in item_scores.keys()})\n",
    "                \n",
    "        \n",
    "        # Ranking de palabras de búsqueda\n",
    "        tf_counter = {}\n",
    "        text_counter = {}\n",
    "        searchs = searchs[::-1]            \n",
    "        for pos, text in enumerate(searchs, 1):\n",
    "            text_counter[text] = tf_counter.get(text, 0) + 1 / np.log10(pos + 1)\n",
    "            for token in text.split():\n",
    "                tf_counter[token] = tf_counter.get(token, 0) + 1 / np.log10(pos + 1)\n",
    "        \n",
    "        for text, tf in text_counter.items():\n",
    "            if text in text2bought:\n",
    "                item_scores = text2bought[text] \n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * tf * W4\\\n",
    "                                  for key in item_scores.keys()})\n",
    "        if text in  text2view:\n",
    "            for text, tf in text_counter.items():\n",
    "                item_scores = text2view[text] \n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * tf * W4\\\n",
    "                                  for key in item_scores.keys()})\n",
    "            \n",
    "        for token, tf in tf_counter.items():\n",
    "            if len(token) < 2:\n",
    "                continue\n",
    "            if token in token2bought:\n",
    "                item_scores = token2bought[token] \n",
    "                tfidf =  tf  / token_df[token]\n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * tfidf * W4\\\n",
    "                                  for key in item_scores.keys()})\n",
    "            if token in token2view:\n",
    "                item_scores = token2view[token] \n",
    "                tfidf =  tf  / token_df[token]\n",
    "                rec_scores.update({key: rec_scores.get(key, 0) + item_scores.get(key, 0) * tfidf * W4\\\n",
    "                                  for key in item_scores.keys()})\n",
    "                \n",
    "        # equivalent to counter.most_common(10)\n",
    "        # https://stackoverflow.com/questions/29240807/python-collections-counter-most-common-complexity\n",
    "        rec = [item for item, _ in heapq.nlargest(10, rec_scores.items(), key=lambda item: item[1])]\n",
    "\n",
    "        # rellena en caso de no tener recomendaciones suficientes\n",
    "        if len(rec) < 10:\n",
    "            if len(rec):\n",
    "                domain = ITEM_TO_DOMAIN[rec[0]]\n",
    "                fill = most_viewed_by_domain.get(domain, []) + most_viewed_items\n",
    "            else:\n",
    "                fill = most_viewed_items\n",
    "\n",
    "            rec = fill_rec(rec, fill)\n",
    "            \n",
    "        # evaluación\n",
    "        model_sum_dcg += dcg(rec, item_bought)\n",
    "        \n",
    "        if (n_recs % 1000) == 0:\n",
    "            print(f\"NDCG: {model_sum_dcg / (IDCG * n_recs): .4f} ({n_recs} recomendaciones)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG (i2i) :  0.2889\n"
     ]
    }
   ],
   "source": [
    "print(f\"NDCG (i2i) : {model_sum_dcg / (IDCG * n_recs): .4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
